{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPaqPKs4ZvVa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.linewidth'] = 6\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from KDG import KDG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cha_h-Smq2z1"
   },
   "outputs": [],
   "source": [
    "widths = [4, 2, 2]\n",
    "num_trials = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzuhRa_v8IrC"
   },
   "source": [
    "# Construct & Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "aA3RJ4NZ8LqF",
    "outputId": "cc729b13-b420-4dc7-e851-e68aa2e93982"
   },
   "outputs": [],
   "source": [
    "def construct_network(X, y, widths):\n",
    "    network = keras.Sequential()\n",
    "    network.add(keras.layers.Dense(widths[0], input_shape = np.shape(X)[1:], activation = 'relu'))\n",
    "    for i in range(1, len(widths)):\n",
    "        network.add(keras.layers.Dense(widths[i], activation = 'relu'))\n",
    "    network.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    network.compile(loss = 'binary_crossentropy', optimizer = keras.optimizers.Adam(1e-3))\n",
    "    network.fit(\n",
    "      X, \n",
    "      y, \n",
    "      epochs = 30, \n",
    "      verbose = False,\n",
    "      batch_size = int(2 ** (np.log(len(X)) / np.log(5) + 1.5))\n",
    "    )\n",
    "\n",
    "    return network\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keurnal Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_AKN(X, y):\n",
    "    X_transform, X, y_transform, y = train_test_split(X, y, test_size = 0.3)\n",
    "    #X_transform, y_transform = X, y\n",
    "    network = construct_network(X_transform, y_transform, widths)\n",
    "\n",
    "    polytope_memberships = []\n",
    "    last_activations = X\n",
    "    \n",
    "    for layer_id in range(len(network.layers)):\n",
    "        weights, bias = network.layers[layer_id].get_weights()\n",
    "        preactivation = np.matmul(last_activations, weights) + bias\n",
    "        if layer_id == len(widths) - 1:\n",
    "            binary_preactivation = (preactivation > 0.5).astype('int')\n",
    "        else:\n",
    "            binary_preactivation = (preactivation > 0).astype('int')\n",
    "        polytope_memberships.append(binary_preactivation)\n",
    "        last_activations = preactivation * binary_preactivation\n",
    "\n",
    "    polytope_memberships = np.concatenate(polytope_memberships, axis = 1)\n",
    "    _, polytope_ids = np.unique(np.matmul(polytope_memberships, 2 ** np.arange(0, np.shape(polytope_memberships)[1])), return_inverse = True)\n",
    "\n",
    "\n",
    "    return KDG().fit(X, y, polytope_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_parity(n):\n",
    "    means = np.array([[-1, -1], [1, 1], [-1, 1], [1, -1]])\n",
    "    X = np.concatenate([np.random.multivariate_normal(mean, 0.1 * np.eye(len(mean)),\n",
    "                                                 size=int(n / 4)) for mean in means])\n",
    "\n",
    "    y = np.concatenate([np.ones(int(n / 4)) * int(idx < 2) for idx in range(len(means))])\n",
    "\n",
    "    random_indices_order = list(range(len(X)))\n",
    "    np.random.shuffle(random_indices_order)\n",
    "    return X[random_indices_order], np.array(y[random_indices_order]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ece(predicted_posterior, y):\n",
    "    hists = []\n",
    "    hists_hat = []\n",
    "    amts = []\n",
    "    num_bins = 40\n",
    "    eces_across_y_vals = []\n",
    "    for y_val in np.unique(y):\n",
    "        for i in range(num_bins):\n",
    "            prop = i*1./num_bins\n",
    "            inds = np.where((predicted_posterior[:, y_val] >= prop) & (predicted_posterior[:, y_val] <= prop+1./num_bins))[0]\n",
    "            amts.append(len(inds))\n",
    "            if len(inds) > 0:\n",
    "                hists.append(len(np.where(y[inds] == y_val)[0])*1./len(inds))\n",
    "                hists_hat.append(np.mean(predicted_posterior[inds, y_val]))\n",
    "            else:\n",
    "                hists.append(prop)\n",
    "                hists_hat.append(prop + 0.5/num_bins)\n",
    "        eces_across_y_vals.append(np.dot(np.abs(np.array(hists) - np.array(hists_hat)), amts) / np.sum(amts))\n",
    "        return np.mean(eces_across_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brier(predicted_posterior, y):\n",
    "    brier_across_y_vals = []\n",
    "    for y_val in np.unique(y):\n",
    "        brier_across_y_vals.append(np.nanmean((predicted_posterior[:, y_val] - (y == y_val).astype('int'))**2))\n",
    "    return np.mean(brier_across_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_mean(ra, low = 25, high = 75):\n",
    "    ra = np.array(ra)\n",
    "    lower_val = np.nanpercentile(ra, low)\n",
    "    higher_val = np.nanpercentile(ra, high)\n",
    "    return np.mean(ra[np.where((ra >= lower_val) & (ra <= higher_val))[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hellinger_explicit(p, q):\n",
    "    \"\"\"Hellinger distance between two discrete distributions.\n",
    "       Same as original version but without list comprehension\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((np.sqrt(p) - np.sqrt(q)) ** 2)) / np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_gaussian_parity(n = int(1e6))\n",
    "X_test, y_test = generate_gaussian_parity(n = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96434bd932544d59af7af28867a11d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xx, yy = np.meshgrid(np.arange(-1, 1, (2) / 100),\n",
    "                      np.arange(-1, 1, (2) / 100))\n",
    "\n",
    "def pdf(x):\n",
    "    mu01, mu02, mu11, mu12 = [[-1, -1], [1, 1], [-1, 1], [1, -1]]\n",
    "    cov = 0.1 * np.eye(2)\n",
    "    inv_cov = np.linalg.inv(cov) \n",
    "\n",
    "    p0 = (\n",
    "        np.exp(-(x - mu01)@inv_cov@(x-mu01).T) \n",
    "        + np.exp(-(x - mu02)@inv_cov@(x-mu02).T)\n",
    "    )/(2*np.pi*np.sqrt(np.linalg.det(cov)))\n",
    "\n",
    "    p1 = (\n",
    "        np.exp(-(x - mu11)@inv_cov@(x-mu11).T) \n",
    "        + np.exp(-(x - mu12)@inv_cov@(x-mu12).T)\n",
    "    )/(2*np.pi*np.sqrt(np.linalg.det(cov)))\n",
    "\n",
    "    return p1/(p0+p1)\n",
    "\n",
    "true_posterior = np.array([pdf(x) for x in tqdm(np.c_[xx.ravel(), yy.ravel()])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_y_proba(X, y, n, X_test):\n",
    "    random_indices = np.random.choice(len(X), int(n))\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    network = construct_network(X, y, widths)\n",
    "    class_1_posteriors = network.predict_proba(X_test)\n",
    "    \n",
    "    class_1_posteriors_grid = network.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "    return np.concatenate([1 - class_1_posteriors, class_1_posteriors], axis = 1), np.concatenate([1 - class_1_posteriors_grid, class_1_posteriors_grid], axis = 1)\n",
    "    \n",
    "\n",
    "def get_KDE_y_proba(X, y, n, X_test):\n",
    "    random_indices = np.random.choice(len(X), int(n))\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    kdg = train_AKN(X, y)\n",
    "    y_proba_unnormalized = kdg.predict_proba(X_test)\n",
    "\n",
    "    y_proba = y_proba_unnormalized.copy()\n",
    "    for y_val in range(np.shape(y_proba)[1]):\n",
    "        y_proba[:, y_val] /= np.sum(y_proba_unnormalized, axis = 1)\n",
    "        \n",
    "    y_proba_unnormalized_grid = kdg.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    y_proba_grid = y_proba_unnormalized_grid.copy()\n",
    "    for y_val in range(np.shape(y_proba)[1]):\n",
    "        y_proba_grid[:, y_val] /= np.sum(y_proba_unnormalized_grid, axis = 1)\n",
    "    \n",
    "    return y_proba, y_proba_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05dc5abe81e42ddb766a8d5033d23a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8f5be544da4131b4a3b25cd92bc132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KDE_acc_means = []\n",
    "network_acc_means = []\n",
    "\n",
    "KDE_acc_stds = []\n",
    "network_acc_stds = []\n",
    "\n",
    "KDE_brier_means = []\n",
    "network_brier_means = []\n",
    "\n",
    "KDE_brier_stds = []\n",
    "network_brier_stds = []\n",
    "n_ra = np.logspace(2.5, 7.5, num = 10, base = 10)\n",
    "ticks = np.arange(np.min(n_ra), np.max(n_ra), step = int((np.max(n_ra) - np.min(n_ra)) // 4))\n",
    "ticks_ra = np.array([int(str(tick)[:1]) * 10 ** int(np.log10(tick)) for tick in ticks])\n",
    "for n in tqdm(n_ra):\n",
    "    network_y_test_proba_across_trials = np.array([get_network_y_proba(X, y, n, X_test) for _ in tqdm(range(num_trials))])\n",
    "    KDE_y_test_proba_across_trials = np.array([get_KDE_y_proba(X, y, n, X_test) for _ in tqdm(range(num_trials))])\n",
    "\n",
    "    \n",
    "    KDE_accs_across_trials = []\n",
    "    network_accs_across_trials = []\n",
    "    KDE_briers_across_trials = []\n",
    "    network_briers_across_trials = []\n",
    "    for trial_idx in range(num_trials):\n",
    "        KDE_accs_across_trials.append(np.nanmean(np.argmax(KDE_y_test_proba_across_trials[trial_idx, 0], axis = 1) == y_test))\n",
    "        network_accs_across_trials.append(np.nanmean(np.argmax(network_y_test_proba_across_trials[trial_idx, 0], axis = 1) == y_test))\n",
    "        \n",
    "        KDE_briers_across_trials.append(hellinger_explicit(KDE_y_test_proba_across_trials[trial_idx, 1][:, 0], true_posterior))\n",
    "        network_briers_across_trials.append(hellinger_explicit(network_y_test_proba_across_trials[trial_idx, 1][:, 0], true_posterior))\n",
    "        \n",
    "    KDE_acc_means.append(clipped_mean(KDE_accs_across_trials, 50, 100))\n",
    "    network_acc_means.append(clipped_mean(network_accs_across_trials, 50, 100))\n",
    "    \n",
    "    KDE_brier_means.append(clipped_mean(KDE_briers_across_trials, 0, 25))\n",
    "    network_brier_means.append(clipped_mean(network_briers_across_trials, 0, 25))\n",
    "\n",
    "    figs, ax = plt.subplots(1, 2, figsize = (18, 9))\n",
    "    figs.set_facecolor(\"white\")\n",
    "\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=27)\n",
    "    ax[0].plot(n_ra[:len(KDE_acc_means)] , KDE_acc_means, label = \"Ours\", c = \"red\")\n",
    "    ax[0].plot(n_ra[:len(KDE_acc_means)], network_acc_means, label = \"Deep Network\", c = \"blue\")\n",
    "    ax[0].hlines(1.0, 0, n_ra[len(KDE_acc_means) - 1], linestyle = \"dashed\", label = \"Perfect Class Prediction\", color = \"black\")\n",
    "    ax[0].legend(fontsize = 18)\n",
    "    ax[0].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "    ax[0].set_ylabel(\"Test Accuracy\", fontsize = 27)\n",
    "    ax[0].set_xscale(\"log\")\n",
    "\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=27)\n",
    "    ax[1].plot(n_ra[:len(KDE_acc_means)] , KDE_brier_means, label = \"Ours\", c = \"red\")\n",
    "    ax[1].plot(n_ra[:len(KDE_acc_means)], network_brier_means, label = \"Deep Network\", c = \"blue\")\n",
    "    ax[1].hlines(0.0, 0, n_ra[len(KDE_acc_means) - 1], linestyle = \"dashed\", label = \"Perfect Calibration\", color = \"black\")\n",
    "    ax[1].legend(fontsize = 18)\n",
    "    ax[1].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "    ax[1].set_ylabel(\"Test Hellinger Distance\", fontsize = 27)\n",
    "    ax[1].set_xscale(\"log\")\n",
    "\n",
    "    figs.tight_layout()\n",
    "\n",
    "    figs.suptitle(\"Posterior Estimation Comparison\\nDataset: Gaussian XOR w/ Sigma=0.1\\nNetwork Widths={}\".format(widths), fontsize=27, y = 1.15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, ax = plt.subplots(1, 2, figsize = (18, 9))\n",
    "figs.set_facecolor(\"white\")\n",
    "\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=27)\n",
    "ax[0].plot(n_ra , KDE_acc_means, label = \"Ours\", c = \"red\")\n",
    "ax[0].plot(n_ra, network_acc_means, label = \"Deep Network\", c = \"blue\")\n",
    "ax[0].hlines(1.0, 0, n_ra[-1], linestyle = \"dashed\", label = \"Perfect Class Prediction\", color = \"black\")\n",
    "ax[0].legend(fontsize = 18)\n",
    "ax[0].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "ax[0].set_ylabel(\"Test Accuracy\", fontsize = 27)\n",
    "ax[0].set_xscale(\"log\")\n",
    "\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=27)\n",
    "ax[1].plot(n_ra , KDE_brier_means, label = \"Ours\", c = \"red\")\n",
    "ax[1].plot(n_ra, network_brier_means, label = \"Deep Network\", c = \"blue\")\n",
    "ax[1].hlines(0.0, 0, n_ra[-1], linestyle = \"dashed\", label = \"Perfect Calibration\", color = \"black\")\n",
    "ax[1].legend(fontsize = 18)\n",
    "ax[1].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "ax[1].set_ylabel(\"Test Hellinger Distance\", fontsize = 27)\n",
    "ax[1].set_xscale(\"log\")\n",
    "\n",
    "\n",
    "figs.tight_layout()\n",
    "\n",
    "figs.suptitle(\"Posterior Estimation Comparison\\nDataset: Gaussian XOR w/ Sigma=0.1\\nNetwork Widths={}\".format(widths), fontsize=27, y = 1.15)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Polytopes",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
