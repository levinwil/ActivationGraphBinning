{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPaqPKs4ZvVa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.linewidth'] = 6\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from KDG import KDG\n",
    "\n",
    "import openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cha_h-Smq2z1"
   },
   "outputs": [],
   "source": [
    "widths = [8, 8]\n",
    "num_trials = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzuhRa_v8IrC"
   },
   "source": [
    "# Construct & Train Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keurnal Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(X, y, widths):\n",
    "    network = keras.Sequential()\n",
    "    network.add(keras.layers.Dense(widths[0], input_shape = np.shape(X)[1:], activation = 'relu'))\n",
    "    for i in range(1, len(widths)):\n",
    "        network.add(keras.layers.Dense(widths[i], activation = 'relu'))\n",
    "    network.add(keras.layers.Dense(len(np.unique(y)), activation = 'softmax'))\n",
    "    network.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(1e-3))\n",
    "    network.fit(\n",
    "      X, \n",
    "      keras.utils.to_categorical(y), \n",
    "      epochs = 100, \n",
    "      verbose = False,\n",
    "      batch_size = int(2 ** (np.log(len(X)) / np.log(5) + 2.2))\n",
    "    )\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_AKN(X, y):\n",
    "    X_transform, X, y_transform, y = train_test_split(X, y, test_size = 0.3)\n",
    "    #X_transform, y_transform = X, y\n",
    "    network = construct_network(X_transform, y_transform, widths)\n",
    "\n",
    "    polytope_memberships = []\n",
    "    last_activations = X\n",
    "    \n",
    "    for layer_id in range(len(network.layers)):\n",
    "        weights, bias = network.layers[layer_id].get_weights()\n",
    "        preactivation = np.matmul(last_activations, weights) + bias\n",
    "        if layer_id == len(widths) - 1:\n",
    "            binary_preactivation = (preactivation > 0.5).astype('int')\n",
    "        else:\n",
    "            binary_preactivation = (preactivation > 0).astype('int')\n",
    "        polytope_memberships.append(binary_preactivation)\n",
    "        last_activations = preactivation * binary_preactivation\n",
    "\n",
    "    polytope_memberships = [np.tensordot(np.concatenate(polytope_memberships, axis = 1), 2 ** np.arange(0, np.shape(np.concatenate(polytope_memberships, axis = 1))[1]), axes = 1)]\n",
    "\n",
    "    return KDG().fit(X, y, polytope_memberships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ece(predicted_posterior, y):\n",
    "    hists = []\n",
    "    hists_hat = []\n",
    "    amts = []\n",
    "    num_bins = 40\n",
    "    eces_across_y_vals = []\n",
    "    for y_val in np.unique(y):\n",
    "        for i in range(num_bins):\n",
    "            prop = i*1./num_bins\n",
    "            inds = np.where((predicted_posterior[:, y_val] >= prop) & (predicted_posterior[:, y_val] <= prop+1./num_bins))[0]\n",
    "            amts.append(len(inds))\n",
    "            if len(inds) > 0:\n",
    "                hists.append(len(np.where(y[inds] == y_val)[0])*1./len(inds))\n",
    "                hists_hat.append(np.mean(predicted_posterior[inds, y_val]))\n",
    "            else:\n",
    "                hists.append(prop)\n",
    "                hists_hat.append(prop + 0.5/num_bins)\n",
    "        eces_across_y_vals.append(np.dot(np.abs(np.array(hists) - np.array(hists_hat)), amts) / np.sum(amts))\n",
    "        return np.mean(eces_across_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "X_train, y_train = X_train[np.where(y_train < 2)[0]], y_train[np.where(y_train < 2)[0]]\n",
    "X_test, y_test = X_test[np.where(y_test < 2)[0]], y_test[np.where(y_test < 2)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = keras.applications.vgg16.VGG16(weights = \"imagenet\", include_top = False, pooling = \"max\", input_shape = np.shape(X_train)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = network.predict(X_train), network.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_train, y_train[:, 0]\n",
    "y_test = y_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_y_proba(X, y, n, X_test):\n",
    "    random_indices = np.random.choice(len(X), int(n), replace = False)\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    network = construct_network(X, y, widths)\n",
    "    return network.predict_proba(X_test)\n",
    "    \n",
    "\n",
    "def get_KDE_y_proba(X, y, n, X_test):\n",
    "    random_indices = np.random.choice(len(X), int(n), replace = False)\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    kdg = train_AKN(X, y)\n",
    "    y_proba_unnormalized = kdg.predict_proba(X_test, pooling = \"class\")\n",
    "\n",
    "    y_proba = y_proba_unnormalized.copy()\n",
    "    for y_val in range(np.shape(y_proba)[1]):\n",
    "        y_proba[:, y_val] /= np.sum(y_proba_unnormalized, axis = 1)\n",
    "        \n",
    "    return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_y_proba(X, y, n, X_test):\n",
    "    random_indices = np.random.choice(len(X), int(n), replace = False)\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    network = construct_network(X, y, widths)\n",
    "    return network.predict_proba(X_test)\n",
    "    \n",
    "\n",
    "    random_indices = np.random.choice(len(X), int(n), replace = False)\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    kdg = train_AKN(X, y)\n",
    "    y_proba_unnormalized = kdg.predict_proba(X_test, pooling = \"class\")\n",
    "\n",
    "    y_proba = y_proba_unnormalized.copy()\n",
    "    for y_val in range(np.shape(y_proba)[1]):\n",
    "        y_proba[:, y_val] /= np.sum(y_proba_unnormalized, axis = 1)\n",
    "        \n",
    "    return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brier(predicted_posterior, y):\n",
    "    brier_across_y_vals = []\n",
    "    for y_val in np.unique(y):\n",
    "        brier_across_y_vals.append(np.nanmean((predicted_posterior[:, y_val] - (y == y_val).astype('int'))**2))\n",
    "    return np.mean(brier_across_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_mean(ra, low = 25, high = 75):\n",
    "    ra = np.array(ra)\n",
    "    lower_val = np.nanpercentile(ra, low)\n",
    "    higher_val = np.nanpercentile(ra, high)\n",
    "    return np.mean(ra[np.where((ra >= lower_val) & (ra <= higher_val))[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2f093d8fb34782881947449b2175d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d48ef1d2093417a86cffb4f93346369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel/__main__.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel/__main__.py:4: RuntimeWarning: Mean of empty slice\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel/__main__.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel/__main__.py:4: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-1d9c19d84459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrial_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mKDE_y_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_KDE_y_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mnetwork_y_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_network_y_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-376cd915d782>\u001b[0m in \u001b[0;36mget_KDE_y_proba\u001b[0;34m(X, y, n, X_test)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mkdg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_AKN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0my_proba_unnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_proba_unnormalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ActivationGraphBinning/KDG.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, pooling)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpolytope_mean_weight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_of_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mlikelihoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolytope_mean_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpolytope_mean_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytope_means_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpolytope_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlikelihoods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0my_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytope_means_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolytope_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolytope_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ActivationGraphBinning/KDG.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpolytope_mean_weight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_of_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mlikelihoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolytope_mean_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpolytope_mean_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytope_means_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpolytope_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlikelihoods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0my_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytope_means_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolytope_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolytope_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ActivationGraphBinning/KDG.py\u001b[0m in \u001b[0;36mcompute_pdf\u001b[0;34m(X, polytope_mean_id)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mweights_of_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytope_means_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolytope_mean_X\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytope_means_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mcovs_of_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytope_means_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolytope_mean_y\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytope_means_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mweights_of_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytope_means_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolytope_mean_y\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytope_means_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mpolytope_mean_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovs_of_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_of_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "KDE_acc_means = []\n",
    "network_acc_means = []\n",
    "\n",
    "KDE_acc_stds = []\n",
    "network_acc_stds = []\n",
    "\n",
    "KDE_brier_means = []\n",
    "network_brier_means = []\n",
    "\n",
    "KDE_brier_stds = []\n",
    "network_brier_stds = []\n",
    "n_ra = np.logspace(3.5, np.log10(len(X)), num = 10, base = 10) * 0.7\n",
    "ticks = np.arange(np.min(n_ra), np.max(n_ra), step = int((np.max(n_ra) - np.min(n_ra)) // 4))\n",
    "ticks_ra = np.array([int(str(tick)[:1]) * 10 ** int(np.log10(tick)) for tick in ticks])\n",
    "for n in tqdm(n_ra):\n",
    "    KDE_accs_across_trials = []\n",
    "    network_accs_across_trials = []\n",
    "    KDE_briers_across_trials = []\n",
    "    network_briers_across_trials = []\n",
    "    for trial_idx in tqdm(range(num_trials)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 / num_trials)\n",
    "        KDE_y_proba = get_KDE_y_proba(X_train, y_train, n, X_test)\n",
    "        network_y_proba = get_network_y_proba(X, y, n, X_test)\n",
    "        \n",
    "        KDE_accs_across_trials.append(np.nanmean(np.argmax(KDE_y_proba, axis = 1) == y_test))\n",
    "        network_accs_across_trials.append(np.nanmean(np.argmax(network_y_proba, axis = 1) == y_test))\n",
    "        \n",
    "        KDE_briers_across_trials.append(get_brier(KDE_y_proba, y_test))\n",
    "        network_briers_across_trials.append(get_brier(network_y_proba, y_test))\n",
    "        \n",
    "    KDE_acc_means.append(np.nanmean(KDE_accs_across_trials))\n",
    "    network_acc_means.append(np.nanmean(network_accs_across_trials))\n",
    "    \n",
    "    KDE_brier_means.append(np.nanmean(KDE_briers_across_trials))\n",
    "    network_brier_means.append(np.nanmean(network_briers_across_trials))\n",
    "    \n",
    "    KDE_acc_stds.append(np.nanstd(KDE_accs_across_trials))\n",
    "    network_acc_stds.append(np.nanstd(network_accs_across_trials))\n",
    "\n",
    "    KDE_brier_stds.append(np.nanstd(KDE_briers_across_trials))\n",
    "    network_brier_stds.append(np.nanstd(network_briers_across_trials))\n",
    "\n",
    "    figs, ax = plt.subplots(1, 2, figsize = (18, 9))\n",
    "    figs.set_facecolor(\"white\")\n",
    "\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=27)\n",
    "    ax[0].plot(n_ra[:len(KDE_acc_means)] , 1 - np.array(KDE_acc_means), label = \"Kernel Density Network (Ours)\", c = \"red\")\n",
    "    ax[0].plot(n_ra[:len(KDE_acc_means)], 1 - np.array(network_acc_means), label = \"Deep Network\", c = \"blue\")\n",
    "    ax[0].hlines(0.0, 0, n_ra[len(KDE_acc_means) - 1], linestyle = \"dashed\", label = \"Perfect\", color = \"black\")\n",
    "    ax[0].legend(fontsize = 18, loc = \"upper right\", frameon = False)\n",
    "    ax[0].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "    ax[0].set_ylabel(\"Test Generalization Error\", fontsize = 27)\n",
    "    ax[0].set_xscale(\"log\")\n",
    "    ax[0].fill_between(n_ra[:len(KDE_acc_means)], \n",
    "                   1 - np.array(KDE_acc_means) - np.array(KDE_acc_stds),\n",
    "                   1 - np.array(KDE_acc_means) + np.array(KDE_acc_stds),\n",
    "                   alpha = .1,\n",
    "                   color = \"red\")\n",
    "    ax[0].fill_between(n_ra[:len(KDE_acc_means)], \n",
    "                   1 - np.array(network_acc_means) - np.array(network_acc_stds),\n",
    "                   1 - np.array(network_acc_means) + np.array(network_acc_stds),\n",
    "                   alpha = .1,\n",
    "                   color = \"blue\")\n",
    "    yticks_range = np.arange(0, 1 - network_acc_means[0] + network_acc_stds[0], (1 - network_acc_means[0] + network_acc_stds[0]) / 100)\n",
    "    ax[0].set_yticks([round(np.percentile(yticks_range, p), 3) for p in [0, 33, 66, 100]])\n",
    "    for side in {\"right\", \"top\"}:\n",
    "            ax[0].spines[side].set_visible(False)\n",
    "\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=27)\n",
    "    ax[1].plot(n_ra[:len(KDE_acc_means)] , KDE_brier_means, c = \"red\")\n",
    "    ax[1].plot(n_ra[:len(KDE_acc_means)], network_brier_means, c = \"blue\")\n",
    "    ax[1].hlines(0.0, 0, n_ra[len(KDE_acc_means) - 1], linestyle = \"dashed\", color = \"black\")\n",
    "    ax[1].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "    ax[1].set_ylabel(\"Test Mean Brier Score\", fontsize = 27)\n",
    "    ax[1].set_xscale(\"log\")\n",
    "    ax[1].fill_between(n_ra[:len(KDE_brier_means)], \n",
    "               np.array(KDE_brier_means) - np.array(KDE_brier_stds),\n",
    "               np.array(KDE_brier_means) + np.array(KDE_brier_stds),\n",
    "               alpha = .1,\n",
    "               color = \"red\")\n",
    "    ax[1].fill_between(n_ra[:len(KDE_brier_means)], \n",
    "                   np.array(network_brier_means) - np.array(network_brier_stds),\n",
    "                   np.array(network_brier_means) + np.array(network_brier_stds),\n",
    "                   alpha = .1,\n",
    "                   color = \"blue\")\n",
    "    yticks_range = np.arange(0, network_brier_means[0] + network_brier_stds[0], (network_brier_means[0] + network_brier_stds[0]) / 100)\n",
    "    ax[1].set_yticks([round(np.percentile(yticks_range, p), 3) for p in [0, 33, 66, 100]])\n",
    "    for side in {\"right\", \"top\"}:\n",
    "            ax[1].spines[side].set_visible(False)\n",
    "\n",
    "    figs.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, ax = plt.subplots(1, 2, figsize = (18, 9))\n",
    "figs.set_facecolor(\"white\")\n",
    "\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=27)\n",
    "ax[0].plot(n_ra , 1 - np.array(KDE_acc_means), label = \"Kernel Density Network (Ours)\", c = \"red\")\n",
    "ax[0].plot(n_ra, 1 - np.array(network_acc_means), label = \"Deep Network\", c = \"blue\")\n",
    "ax[0].hlines(0.0, 0, n_ra[-1], linestyle = \"dashed\", label = \"Perfect\", color = \"black\")\n",
    "ax[0].legend(fontsize = 18, loc = \"upper right\", frameon = False)\n",
    "ax[0].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "ax[0].set_ylabel(\"Test Generalization Error\", fontsize = 27)\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[0].fill_between(n_ra, \n",
    "                   1 - np.array(KDE_acc_means) - np.array(KDE_acc_stds),\n",
    "                   1 - np.array(KDE_acc_means) + np.array(KDE_acc_stds),\n",
    "                   alpha = .1,\n",
    "                   color = \"red\")\n",
    "ax[0].fill_between(n_ra, \n",
    "               1 - np.array(network_acc_means) - np.array(network_acc_stds),\n",
    "               1 - np.array(network_acc_means) + np.array(network_acc_stds),\n",
    "               alpha = .1,\n",
    "               color = \"blue\")\n",
    "yticks_range = np.arange(0, 1 - network_acc_means[0] + network_acc_stds[0], (1 - network_acc_means[0] + network_acc_stds[0]) / 100)\n",
    "ax[0].set_yticks([round(np.percentile(yticks_range, p), 3) for p in [0, 33, 66, 100]])\n",
    "for side in {\"right\", \"top\"}:\n",
    "        ax[0].spines[side].set_visible(False)\n",
    "\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=27)\n",
    "ax[1].plot(n_ra , KDE_brier_means, c = \"red\")\n",
    "ax[1].plot(n_ra, network_brier_means, c = \"blue\")\n",
    "ax[1].hlines(0.0, 0, n_ra[-1], linestyle = \"dashed\", color = \"black\")\n",
    "ax[1].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "ax[1].set_ylabel(\"Test Mean brier Score\", fontsize = 27)\n",
    "ax[1].set_xscale(\"log\")\n",
    "ax[1].fill_between(n_ra, \n",
    "               np.array(KDE_brier_means) - np.array(KDE_brier_stds),\n",
    "               np.array(KDE_brier_means) + np.array(KDE_brier_stds),\n",
    "               alpha = .1,\n",
    "               color = \"red\")\n",
    "ax[1].fill_between(n_ra, \n",
    "               np.array(network_brier_means) - np.array(network_brier_stds),\n",
    "               np.array(network_brier_means) + np.array(network_brier_stds),\n",
    "               alpha = .1,\n",
    "               color = \"blue\")\n",
    "yticks_range = np.arange(0, network_brier_means[0] + network_brier_stds[0], (network_brier_means[0] + network_brier_stds[0]) / 100)\n",
    "ax[1].set_yticks([round(np.percentile(yticks_range, p), 3) for p in [0, 33, 66, 100]])\n",
    "for side in {\"right\", \"top\"}:\n",
    "        ax[1].spines[side].set_visible(False)\n",
    "\n",
    "\n",
    "figs.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Polytopes",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
