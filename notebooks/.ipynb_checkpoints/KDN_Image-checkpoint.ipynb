{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPaqPKs4ZvVa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.linewidth'] = 6\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from KDG import KDG\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cha_h-Smq2z1"
   },
   "outputs": [],
   "source": [
    "num_trials = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzuhRa_v8IrC"
   },
   "source": [
    "# Construct & Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "aA3RJ4NZ8LqF",
    "outputId": "cc729b13-b420-4dc7-e851-e68aa2e93982"
   },
   "outputs": [],
   "source": [
    "def construct_network(X, y):\n",
    "    network = keras.Sequential()\n",
    "\n",
    "    network.add(keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=np.shape(X)[1:]))\n",
    "    network.add(keras.layers.AveragePooling2D())\n",
    "    \n",
    "    network.add(keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=np.shape(X)[1:]))\n",
    "    network.add(keras.layers.AveragePooling2D())\n",
    "\n",
    "    network.add(keras.layers.Flatten())\n",
    "\n",
    "    network.add(keras.layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "    network.add(keras.layers.Dense(units=16, activation='relu'))\n",
    "    \n",
    "    network.add(keras.layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "    network.add(keras.layers.Dense(units=len(np.unique(y)), activation = 'softmax'))\n",
    "    network.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(3e-3))\n",
    "    network.fit(\n",
    "      X, \n",
    "      keras.utils.to_categorical(y), \n",
    "      epochs = 60, \n",
    "      verbose = False,\n",
    "      batch_size = int(2 ** (np.log(len(X)) / np.log(5) + 2.2))\n",
    "    )\n",
    "\n",
    "    return network\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keurnal Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_AKN(X, y):\n",
    "    X_transform, X, y_transform, y = train_test_split(X, y, test_size = 0.5)\n",
    "    #X_transform, y_transform = X, y\n",
    "    network = construct_network(X_transform, y_transform)\n",
    "    \n",
    "    encoder = keras.models.Model(network.inputs, network.layers[5].output)\n",
    "    X = encoder.predict(X)\n",
    "    polytope_memberships = []\n",
    "    last_activations = X\n",
    "    for layer_id in range(6, len(network.layers)):\n",
    "        weights, bias = network.layers[layer_id].get_weights()\n",
    "        preactivation = np.matmul(last_activations, weights) + bias\n",
    "        if layer_id == len(network.layers) - 1:\n",
    "            binary_preactivation = (preactivation > 0.5).astype('int')\n",
    "        else:\n",
    "            binary_preactivation = (preactivation > 0).astype('int')\n",
    "        polytope_memberships.append(binary_preactivation)\n",
    "        last_activations = preactivation * binary_preactivation\n",
    "\n",
    "    polytope_memberships = np.concatenate(polytope_memberships, axis = 1)\n",
    "    _, polytope_ids = np.unique(np.matmul(polytope_memberships, 2 ** np.arange(0, np.shape(polytope_memberships)[1])), return_inverse = True)\n",
    "\n",
    "\n",
    "    kdg = KDG().fit(X, y, polytope_ids)\n",
    "    return kdg, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_mean(ra, low = 25, high = 75):\n",
    "    ra = np.array(ra)\n",
    "    lower_val = np.nanpercentile(ra, low)\n",
    "    higher_val = np.nanpercentile(ra, high)\n",
    "    return np.mean(ra[np.where((ra >= lower_val) & (ra <= higher_val))[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ece(predicted_posterior, y):\n",
    "    hists = []\n",
    "    hists_hat = []\n",
    "    amts = []\n",
    "    num_bins = 10\n",
    "    eces_across_y_vals = []\n",
    "    for y_val in np.unique(y):\n",
    "        for i in range(num_bins):\n",
    "            prop = i*1./num_bins\n",
    "            inds = np.where((predicted_posterior[:, y_val] >= prop) & (predicted_posterior[:, y_val] <= prop+1./num_bins))[0]\n",
    "            amts.append(len(inds))\n",
    "            if len(inds) > 0:\n",
    "                hists.append(len(np.where(y[inds] == y_val)[0])*1./len(inds))\n",
    "                hists_hat.append(np.mean(predicted_posterior[inds, y_val]))\n",
    "            else:\n",
    "                hists.append(prop)\n",
    "                hists_hat.append(prop + 0.5/num_bins)\n",
    "        eces_across_y_vals.append(np.dot(np.abs(np.array(hists) - np.array(hists_hat)), amts) / np.sum(amts))\n",
    "        return np.mean(eces_across_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brier(predicted_posterior, y):\n",
    "    brier_across_y_vals = []\n",
    "    for y_val in np.unique(y):\n",
    "        brier_across_y_vals.append(np.nanmean((predicted_posterior[:, y_val] - (y == y_val).astype('int'))**2))\n",
    "    return np.mean(brier_across_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(X, y), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "train_indices, test_indices = np.where(y < 5)[0], np.where(y_test < 5)[0]\n",
    "X, y = np.expand_dims(X[train_indices], axis = -1), y[train_indices]\n",
    "X_test, y_test = np.expand_dims(X_test[test_indices], axis = -1), y_test[test_indices]\n",
    "\n",
    "test_indices = np.random.choice(range(len(X_test)), 1000)\n",
    "X_test, y_test = X_test[test_indices], y_test[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(X, y), (X_test, y_test) = keras.datasets.cifar10.load_data()\\ntrain_indices, test_indices = np.where(y < 2)[0], np.where(y_test < 2)[0]\\nX, y = X[train_indices], y[train_indices, 0]\\nX_test, y_test = X_test[test_indices], y_test[test_indices, 0]\\n\\ntest_indices = np.random.choice(range(len(X_test)), 1000)\\nX_test, y_test = X_test[test_indices], y_test[test_indices]\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "(X, y), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "train_indices, test_indices = np.where(y < 2)[0], np.where(y_test < 2)[0]\n",
    "X, y = X[train_indices], y[train_indices, 0]\n",
    "X_test, y_test = X_test[test_indices], y_test[test_indices, 0]\n",
    "\n",
    "test_indices = np.random.choice(range(len(X_test)), 1000)\n",
    "X_test, y_test = X_test[test_indices], y_test[test_indices]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_y_proba(X, y, n, X_test):\n",
    "    random_indices = np.random.choice(len(X), int(n))\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    network = construct_network(X, y)\n",
    "    return network.predict_proba(X_test)\n",
    "    \n",
    "    \n",
    "\n",
    "def get_KDE_y_proba(X, y, n, X_test):\n",
    "    random_indices = np.random.choice(len(X), int(n))\n",
    "    kdg, encoder = train_AKN(X, y)\n",
    "    X, y = encoder.predict(X[random_indices]), y[random_indices]\n",
    "    X_test = encoder.predict(X_test)\n",
    "    y_proba_test = kdg.predict_proba(X_test)\n",
    "    y_proba_test_normalized = np.copy(y_proba_test)\n",
    "    for y_val in range(np.shape(y_proba_test)[1]):\n",
    "        y_proba_test_normalized[:, y_val] /= np.sum(y_proba_test, axis = 1)\n",
    "    return y_proba_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a18b9b858c34503b17edbe648c03b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b90a656aa5a45539bff3e1832d5a86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KDE_acc_means = []\n",
    "network_acc_means = []\n",
    "\n",
    "KDE_acc_stds = []\n",
    "network_acc_stds = []\n",
    "\n",
    "KDE_ece_means = []\n",
    "network_ece_means = []\n",
    "\n",
    "KDE_ece_stds = []\n",
    "network_ece_stds = []\n",
    "n_ra = np.logspace(2.5, 7, num = 10, base = 10)\n",
    "ticks = np.arange(np.min(n_ra), np.max(n_ra), step = int((np.max(n_ra) - np.min(n_ra)) // 4))\n",
    "ticks_ra = np.array([int(str(tick)[:1]) * 10 ** int(np.log10(tick)) for tick in ticks])\n",
    "for n in tqdm(n_ra):\n",
    "    KDE_y_test_proba_across_trials = np.array([get_KDE_y_proba(X, y, n, X_test) for _ in tqdm(range(num_trials))])\n",
    "    network_y_test_proba_across_trials = np.array([get_network_y_proba(X, y, n, X_test) for _ in tqdm(range(num_trials))])\n",
    "\n",
    "    \n",
    "    KDE_accs_across_trials = []\n",
    "    network_accs_across_trials = []\n",
    "    KDE_eces_across_trials = []\n",
    "    network_eces_across_trials = []\n",
    "    for trial_idx in range(num_trials):\n",
    "        KDE_accs_across_trials.append(np.nanmean(np.argmax(KDE_y_test_proba_across_trials[trial_idx], axis = 1) == y_test))\n",
    "        network_accs_across_trials.append(np.nanmean(np.argmax(network_y_test_proba_across_trials[trial_idx], axis = 1) == y_test))\n",
    "        \n",
    "        KDE_eces_across_trials.append(get_ece(KDE_y_test_proba_across_trials[trial_idx], y_test))\n",
    "        network_eces_across_trials.append(get_ece(network_y_test_proba_across_trials[trial_idx], y_test))\n",
    "        \n",
    "    KDE_acc_means.append(clipped_mean(KDE_accs_across_trials, 50, 100))\n",
    "    network_acc_means.append(clipped_mean(network_accs_across_trials, 50, 100))\n",
    "    \n",
    "    KDE_ece_means.append(clipped_mean(KDE_eces_across_trials, 0, 50))\n",
    "    network_ece_means.append(clipped_mean(network_eces_across_trials, 0, 50))\n",
    "\n",
    "    figs, ax = plt.subplots(1, 2, figsize = (18, 9))\n",
    "    figs.set_facecolor(\"white\")\n",
    "\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=27)\n",
    "    ax[0].plot(n_ra[:len(KDE_acc_means)] , KDE_acc_means, label = \"Ours\", c = \"red\")\n",
    "    ax[0].plot(n_ra[:len(KDE_acc_means)], network_acc_means, label = \"Deep Network\", c = \"blue\")\n",
    "    ax[0].hlines(1.0, 0, n_ra[len(KDE_acc_means) - 1], linestyle = \"dashed\", label = \"Perfect Class Prediction\", color = \"black\")\n",
    "    ax[0].legend(fontsize = 18)\n",
    "    ax[0].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "    ax[0].set_ylabel(\"Test Accuracy\", fontsize = 27)\n",
    "    ax[0].set_xscale(\"log\")\n",
    "\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=27)\n",
    "    ax[1].plot(n_ra[:len(KDE_acc_means)] , KDE_ece_means, label = \"Ours\", c = \"red\")\n",
    "    ax[1].plot(n_ra[:len(KDE_acc_means)], network_ece_means, label = \"Deep Network\", c = \"blue\")\n",
    "    ax[1].hlines(0.0, 0, n_ra[len(KDE_acc_means) - 1], linestyle = \"dashed\", label = \"Perfect Calibration\", color = \"black\")\n",
    "    ax[1].legend(fontsize = 18)\n",
    "    ax[1].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "    ax[1].set_ylabel(\"Test mECE\", fontsize = 27)\n",
    "    ax[1].set_xscale(\"log\")\n",
    "\n",
    "    figs.tight_layout()\n",
    "\n",
    "    figs.suptitle(\"Posterior Estimation Comparison\\nDataset: MNIST\", fontsize=27, y = 1.15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, ax = plt.subplots(1, 2, figsize = (18, 9))\n",
    "figs.set_facecolor(\"white\")\n",
    "\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=27)\n",
    "ax[0].plot(n_ra , KDE_acc_means, label = \"Ours\", c = \"red\")\n",
    "ax[0].plot(n_ra, network_acc_means, label = \"Deep Network\", c = \"blue\")\n",
    "ax[0].hlines(1.0, 0, n_ra[-1], linestyle = \"dashed\", label = \"Perfect Class Prediction\", color = \"black\")\n",
    "ax[0].legend(fontsize = 18)\n",
    "ax[0].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "ax[0].set_ylabel(\"Test Accuracy\", fontsize = 27)\n",
    "ax[0].set_xscale(\"log\")\n",
    "\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=27)\n",
    "ax[1].plot(n_ra , KDE_brier_means, label = \"Ours\", c = \"red\")\n",
    "ax[1].plot(n_ra, network_brier_means, label = \"Deep Network\", c = \"blue\")\n",
    "ax[1].hlines(0.0, 0, n_ra[-1], linestyle = \"dashed\", label = \"Perfect Calibration\", color = \"black\")\n",
    "ax[1].legend(fontsize = 18)\n",
    "ax[1].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "ax[1].set_ylabel(\"Test mECE\", fontsize = 27)\n",
    "ax[1].set_xscale(\"log\")\n",
    "\n",
    "\n",
    "figs.tight_layout()\n",
    "\n",
    "figs.suptitle(\"Posterior Estimation Comparison\\nDataset: MNIST\", fontsize=27, y = 1.15)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Polytopes",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
