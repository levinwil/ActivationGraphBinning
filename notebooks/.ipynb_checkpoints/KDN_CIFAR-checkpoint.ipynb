{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPaqPKs4ZvVa"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.linewidth'] = 6\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from KDG import KDG\n",
    "\n",
    "import openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cha_h-Smq2z1"
   },
   "outputs": [],
   "source": [
    "widths = [4, 3, 2]\n",
    "num_trials = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzuhRa_v8IrC"
   },
   "source": [
    "# Construct & Train Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keurnal Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_network(X, y, widths):\n",
    "    network = keras.Sequential()\n",
    "    network.add(keras.layers.Dense(widths[0], input_shape = np.shape(X)[1:], activation = 'relu'))\n",
    "    for i in range(1, len(widths)):\n",
    "        network.add(keras.layers.Dense(widths[i], activation = 'relu'))\n",
    "    network.add(keras.layers.Dense(len(np.unique(y)), activation = 'softmax'))\n",
    "    network.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(1e-3))\n",
    "    network.fit(\n",
    "      X, \n",
    "      keras.utils.to_categorical(y), \n",
    "      epochs = 100, \n",
    "      verbose = False,\n",
    "      batch_size = int(2 ** (np.log(len(X)) / np.log(5) + 2.2))\n",
    "    )\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_AKN(X, y):\n",
    "    X_transform, X, y_transform, y = train_test_split(X, y, test_size = 0.3)\n",
    "    #X_transform, y_transform = X, y\n",
    "    network = construct_network(X_transform, y_transform, widths)\n",
    "\n",
    "    polytope_memberships = []\n",
    "    last_activations = X\n",
    "    \n",
    "    for layer_id in range(len(network.layers)):\n",
    "        weights, bias = network.layers[layer_id].get_weights()\n",
    "        preactivation = np.matmul(last_activations, weights) + bias\n",
    "        if layer_id == len(widths) - 1:\n",
    "            binary_preactivation = (preactivation > 0.5).astype('int')\n",
    "        else:\n",
    "            binary_preactivation = (preactivation > 0).astype('int')\n",
    "        polytope_memberships.append(binary_preactivation)\n",
    "        last_activations = preactivation * binary_preactivation\n",
    "\n",
    "    polytope_memberships = [np.tensordot(np.concatenate(polytope_memberships, axis = 1), 2 ** np.arange(0, np.shape(np.concatenate(polytope_memberships, axis = 1))[1]), axes = 1)]\n",
    "\n",
    "    return KDG().fit(X, y, polytope_memberships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ece(predicted_posterior, y):\n",
    "    hists = []\n",
    "    hists_hat = []\n",
    "    amts = []\n",
    "    num_bins = 40\n",
    "    eces_across_y_vals = []\n",
    "    for y_val in np.unique(y):\n",
    "        for i in range(num_bins):\n",
    "            prop = i*1./num_bins\n",
    "            inds = np.where((predicted_posterior[:, y_val] >= prop) & (predicted_posterior[:, y_val] <= prop+1./num_bins))[0]\n",
    "            amts.append(len(inds))\n",
    "            if len(inds) > 0:\n",
    "                hists.append(len(np.where(y[inds] == y_val)[0])*1./len(inds))\n",
    "                hists_hat.append(np.mean(predicted_posterior[inds, y_val]))\n",
    "            else:\n",
    "                hists.append(prop)\n",
    "                hists_hat.append(prop + 0.5/num_bins)\n",
    "        eces_across_y_vals.append(np.dot(np.abs(np.array(hists) - np.array(hists_hat)), amts) / np.sum(amts))\n",
    "        return np.mean(eces_across_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = keras.applications.vgg16.VGG16(weights = \"imagenet\", include_top = False, pooling = \"max\", input_shape = np.shape(X_train)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = network.predict(X_train), network.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_train, y_train[:, 0]\n",
    "y_test = y_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_y_proba(X, y, n, X_test):\n",
    "    random_indices = np.random.choice(len(X), int(n), replace = False)\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    network = construct_network(X, y, widths)\n",
    "    return network.predict_proba(X_test)\n",
    "    \n",
    "\n",
    "def get_KDE_y_proba(X, y, n, X_test):\n",
    "    random_indices = np.random.choice(len(X), int(n), replace = False)\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    kdg = train_AKN(X, y)\n",
    "    y_proba_unnormalized = kdg.predict_proba(X_test, pooling = \"polytope\")\n",
    "\n",
    "    y_proba = y_proba_unnormalized.copy()\n",
    "    for y_val in range(np.shape(y_proba)[1]):\n",
    "        y_proba[:, y_val] /= np.sum(y_proba_unnormalized, axis = 1)\n",
    "        \n",
    "    return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_y_proba(X, y, n, X_test):\n",
    "    random_indices = np.random.choice(len(X), int(n), replace = False)\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    network = construct_network(X, y, widths)\n",
    "    return network.predict_proba(X_test)\n",
    "    \n",
    "\n",
    "    random_indices = np.random.choice(len(X), int(n), replace = False)\n",
    "    X, y = X[random_indices], y[random_indices]\n",
    "    kdg = train_AKN(X, y)\n",
    "    y_proba_unnormalized = kdg.predict_proba(X_test, pooling = \"polytope\")\n",
    "\n",
    "    y_proba = y_proba_unnormalized.copy()\n",
    "    for y_val in range(np.shape(y_proba)[1]):\n",
    "        y_proba[:, y_val] /= np.sum(y_proba_unnormalized, axis = 1)\n",
    "        \n",
    "    return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brier(predicted_posterior, y):\n",
    "    brier_across_y_vals = []\n",
    "    for y_val in np.unique(y):\n",
    "        brier_across_y_vals.append(np.nanmean((predicted_posterior[:, y_val] - (y == y_val).astype('int'))**2))\n",
    "    return np.mean(brier_across_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_mean(ra, low = 25, high = 75):\n",
    "    ra = np.array(ra)\n",
    "    lower_val = np.nanpercentile(ra, low)\n",
    "    higher_val = np.nanpercentile(ra, high)\n",
    "    return np.mean(ra[np.where((ra >= lower_val) & (ra <= higher_val))[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KDE_acc_means = []\n",
    "network_acc_means = []\n",
    "\n",
    "KDE_acc_stds = []\n",
    "network_acc_stds = []\n",
    "\n",
    "KDE_brier_means = []\n",
    "network_brier_means = []\n",
    "\n",
    "KDE_brier_stds = []\n",
    "network_brier_stds = []\n",
    "n_ra = np.logspace(3.5, np.log10(len(X)), num = 10, base = 10) * 0.7\n",
    "ticks = np.arange(np.min(n_ra), np.max(n_ra), step = int((np.max(n_ra) - np.min(n_ra)) // 4))\n",
    "ticks_ra = np.array([int(str(tick)[:1]) * 10 ** int(np.log10(tick)) for tick in ticks])\n",
    "for n in tqdm(n_ra):\n",
    "    KDE_accs_across_trials = []\n",
    "    network_accs_across_trials = []\n",
    "    KDE_briers_across_trials = []\n",
    "    network_briers_across_trials = []\n",
    "    for trial_idx in tqdm(range(num_trials)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 / num_trials)\n",
    "        KDE_y_proba = get_KDE_y_proba(X_train, y_train, n, X_test)\n",
    "        network_y_proba = get_network_y_proba(X, y, n, X_test)\n",
    "        \n",
    "        KDE_accs_across_trials.append(np.nanmean(np.argmax(KDE_y_proba, axis = 1) == y_test))\n",
    "        network_accs_across_trials.append(np.nanmean(np.argmax(network_y_proba, axis = 1) == y_test))\n",
    "        \n",
    "        KDE_briers_across_trials.append(get_brier(KDE_y_proba, y_test))\n",
    "        network_briers_across_trials.append(get_brier(network_y_proba, y_test))\n",
    "        \n",
    "    KDE_acc_means.append(np.nanmean(KDE_accs_across_trials))\n",
    "    network_acc_means.append(np.nanmean(network_accs_across_trials))\n",
    "    \n",
    "    KDE_brier_means.append(np.nanmean(KDE_briers_across_trials))\n",
    "    network_brier_means.append(np.nanmean(network_briers_across_trials))\n",
    "    \n",
    "    KDE_acc_stds.append(np.nanstd(KDE_accs_across_trials))\n",
    "    network_acc_stds.append(np.nanstd(network_accs_across_trials))\n",
    "\n",
    "    KDE_brier_stds.append(np.nanstd(KDE_briers_across_trials))\n",
    "    network_brier_stds.append(np.nanstd(network_briers_across_trials))\n",
    "\n",
    "    figs, ax = plt.subplots(1, 2, figsize = (18, 9))\n",
    "    figs.set_facecolor(\"white\")\n",
    "\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=27)\n",
    "    ax[0].plot(n_ra[:len(KDE_acc_means)] , 1 - np.array(KDE_acc_means), label = \"Kernel Density Network (Ours)\", c = \"red\")\n",
    "    ax[0].plot(n_ra[:len(KDE_acc_means)], 1 - np.array(network_acc_means), label = \"Deep Network\", c = \"blue\")\n",
    "    ax[0].hlines(0.0, 0, n_ra[len(KDE_acc_means) - 1], linestyle = \"dashed\", label = \"Perfect\", color = \"black\")\n",
    "    ax[0].legend(fontsize = 18, loc = \"upper right\", frameon = False)\n",
    "    ax[0].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "    ax[0].set_ylabel(\"Test Generalization Error\", fontsize = 27)\n",
    "    ax[0].set_xscale(\"log\")\n",
    "    ax[0].fill_between(n_ra[:len(KDE_acc_means)], \n",
    "                   1 - np.array(KDE_acc_means) - np.array(KDE_acc_stds),\n",
    "                   1 - np.array(KDE_acc_means) + np.array(KDE_acc_stds),\n",
    "                   alpha = .1,\n",
    "                   color = \"red\")\n",
    "    ax[0].fill_between(n_ra[:len(KDE_acc_means)], \n",
    "                   1 - np.array(network_acc_means) - np.array(network_acc_stds),\n",
    "                   1 - np.array(network_acc_means) + np.array(network_acc_stds),\n",
    "                   alpha = .1,\n",
    "                   color = \"blue\")\n",
    "    yticks_range = np.arange(0, 1 - network_acc_means[0] + network_acc_stds[0], (1 - network_acc_means[0] + network_acc_stds[0]) / 100)\n",
    "    ax[0].set_yticks([round(np.percentile(yticks_range, p), 3) for p in [0, 33, 66, 100]])\n",
    "    for side in {\"right\", \"top\"}:\n",
    "            ax[0].spines[side].set_visible(False)\n",
    "\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=27)\n",
    "    ax[1].plot(n_ra[:len(KDE_acc_means)] , KDE_brier_means, c = \"red\")\n",
    "    ax[1].plot(n_ra[:len(KDE_acc_means)], network_brier_means, c = \"blue\")\n",
    "    ax[1].hlines(0.0, 0, n_ra[len(KDE_acc_means) - 1], linestyle = \"dashed\", color = \"black\")\n",
    "    ax[1].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "    ax[1].set_ylabel(\"Test Mean Brier Score\", fontsize = 27)\n",
    "    ax[1].set_xscale(\"log\")\n",
    "    ax[1].fill_between(n_ra[:len(KDE_brier_means)], \n",
    "               np.array(KDE_brier_means) - np.array(KDE_brier_stds),\n",
    "               np.array(KDE_brier_means) + np.array(KDE_brier_stds),\n",
    "               alpha = .1,\n",
    "               color = \"red\")\n",
    "    ax[1].fill_between(n_ra[:len(KDE_brier_means)], \n",
    "                   np.array(network_brier_means) - np.array(network_brier_stds),\n",
    "                   np.array(network_brier_means) + np.array(network_brier_stds),\n",
    "                   alpha = .1,\n",
    "                   color = \"blue\")\n",
    "    yticks_range = np.arange(0, network_brier_means[0] + network_brier_stds[0], (network_brier_means[0] + network_brier_stds[0]) / 100)\n",
    "    ax[1].set_yticks([round(np.percentile(yticks_range, p), 3) for p in [0, 33, 66, 100]])\n",
    "    for side in {\"right\", \"top\"}:\n",
    "            ax[1].spines[side].set_visible(False)\n",
    "\n",
    "    figs.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, ax = plt.subplots(1, 2, figsize = (18, 9))\n",
    "figs.set_facecolor(\"white\")\n",
    "\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=27)\n",
    "ax[0].plot(n_ra , 1 - np.array(KDE_acc_means), label = \"Kernel Density Network (Ours)\", c = \"red\")\n",
    "ax[0].plot(n_ra, 1 - np.array(network_acc_means), label = \"Deep Network\", c = \"blue\")\n",
    "ax[0].hlines(0.0, 0, n_ra[-1], linestyle = \"dashed\", label = \"Perfect\", color = \"black\")\n",
    "ax[0].legend(fontsize = 18, loc = \"upper right\", frameon = False)\n",
    "ax[0].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "ax[0].set_ylabel(\"Test Generalization Error\", fontsize = 27)\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[0].fill_between(n_ra, \n",
    "                   1 - np.array(KDE_acc_means) - np.array(KDE_acc_stds),\n",
    "                   1 - np.array(KDE_acc_means) + np.array(KDE_acc_stds),\n",
    "                   alpha = .1,\n",
    "                   color = \"red\")\n",
    "ax[0].fill_between(n_ra, \n",
    "               1 - np.array(network_acc_means) - np.array(network_acc_stds),\n",
    "               1 - np.array(network_acc_means) + np.array(network_acc_stds),\n",
    "               alpha = .1,\n",
    "               color = \"blue\")\n",
    "yticks_range = np.arange(0, 1 - network_acc_means[0] + network_acc_stds[0], (1 - network_acc_means[0] + network_acc_stds[0]) / 100)\n",
    "ax[0].set_yticks([round(np.percentile(yticks_range, p), 3) for p in [0, 33, 66, 100]])\n",
    "for side in {\"right\", \"top\"}:\n",
    "        ax[0].spines[side].set_visible(False)\n",
    "\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=27)\n",
    "ax[1].plot(n_ra , KDE_brier_means, c = \"red\")\n",
    "ax[1].plot(n_ra, network_brier_means, c = \"blue\")\n",
    "ax[1].hlines(0.0, 0, n_ra[-1], linestyle = \"dashed\", color = \"black\")\n",
    "ax[1].set_xlabel(\"Number of Training Samples (logscale)\", fontsize = 27)\n",
    "ax[1].set_ylabel(\"Test Mean brier Score\", fontsize = 27)\n",
    "ax[1].set_xscale(\"log\")\n",
    "ax[1].fill_between(n_ra, \n",
    "               np.array(KDE_brier_means) - np.array(KDE_brier_stds),\n",
    "               np.array(KDE_brier_means) + np.array(KDE_brier_stds),\n",
    "               alpha = .1,\n",
    "               color = \"red\")\n",
    "ax[1].fill_between(n_ra, \n",
    "               np.array(network_brier_means) - np.array(network_brier_stds),\n",
    "               np.array(network_brier_means) + np.array(network_brier_stds),\n",
    "               alpha = .1,\n",
    "               color = \"blue\")\n",
    "yticks_range = np.arange(0, network_brier_means[0] + network_brier_stds[0], (network_brier_means[0] + network_brier_stds[0]) / 100)\n",
    "ax[1].set_yticks([round(np.percentile(yticks_range, p), 3) for p in [0, 33, 66, 100]])\n",
    "for side in {\"right\", \"top\"}:\n",
    "        ax[1].spines[side].set_visible(False)\n",
    "\n",
    "\n",
    "figs.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Polytopes",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
